# Importation des d√©pendances
import pandas as pd
import streamlit as st
from data_loader import load_happiness_all_df

# Configuration de la page principale
st.set_page_config(
    page_title="Harmonisation des datasets World Happiness Report 2015-2019",
    page_icon="‚ôªÔ∏è",
    layout="centered",
    initial_sidebar_state = "expanded"
)

st.sidebar.subheader("Harmonisation des diff√©rents datasets (2015 - 2019) ‚ôªÔ∏è")

# ===========================================================================================================================
st.title("Harmonisation des datasets : World Happiness Report")

# =============================================================================================================================
st.subheader("Analyse de nos datasets")

# Mise en cache et Chargement des datasets
loaded_data = load_happiness_all_df()

if loaded_data is None:
    st.error("√âchec du chargement des fichiers de donn√©es brutes. V√©rifiez le dossier '/data'.")
    st.stop() # Arr√™te l'ex√©cution de la page si les donn√©es sont manquantes

df_2015, df_2016, df_2017, df_2018, df_2019 = loaded_data

# Cr√©ation des colonnes
col_2015_2017, col_2016_2018 = st.columns(2)
col_2019_1, col_2019_2, col_2019_3 = st.columns(3)

# Affichage de nos dataframes
with col_2015_2017 :
    st.write("Dataframe de l'ann√©e 2015")
   
    st.dataframe(df_2015, use_container_width=True)
    st.write("Dataframe de l'ann√©e 2017")
    st.dataframe(df_2017, use_container_width=True)

with col_2016_2018 :
    st.write("Dataframe de l'ann√©e 2016")
    st.dataframe(df_2016, use_container_width=True)
    st.write("Dataframe de l'ann√©e 2018")
    st.dataframe(df_2018, use_container_width=True)

with col_2019_2 :
    st.write("Dataframe de l'ann√©e 2019")
    st.dataframe(df_2019, use_container_width=True)


st.markdown("""
    #### Contexte du Jeu de Donn√©es

    Les donn√©es utilis√©es dans ce projet proviennent du **World Happiness Report**, une enqu√™te annuelle de r√©f√©rence sur l'√©tat du bonheur mondial.  
    Pour notre analyse, nous disposons de cinq jeux de donn√©es distincts, couvrant les ann√©es **2015, 2016, 2017, 2018 et 2019**.

    Le c≈ìur de ce rapport est le **Score de Bonheur (Happiness Score)**, une m√©trique bas√©e sur *l'√©chelle de Cantril*, qui demande aux citoyens d'√©valuer leur vie sur une √©chelle de 0 (la pire vie possible) √† 10 (la meilleure vie possible).  

    Pour expliquer les variations de ce score, le rapport fournit des donn√©es sur six facteurs cl√©s :  
    - **PIB par Habitant** (Richesse √©conomique)  
    - **Soutien Social** (Famille, amis)  
    - **Esp√©rance de Vie en Bonne Sant√©** (Sant√©)  
    - **Libert√©** (Libert√© de faire ses choix de vie)  
    - **G√©n√©rosit√©**  
    - **Confiance** (Perception de la corruption)  
            
    ---

    #### Le D√©fi : 5 Fichiers, 5 Sch√©mas Diff√©rents

    Notre objectif principal est d'analyser **l'√©volution temporelle du bonheur et de ses composantes de 2015 √† 2019**.  
    Pour ce faire, il est indispensable de **combiner nos 5 fichiers CSV en un seul et unique jeu de donn√©es**.

    Cependant, une simple concat√©nation est impossible. En inspectant les fichiers, nous constatons qu'ils sont **inh√©rents et incoh√©rents**. Bien qu'ils traitent du m√™me sujet, leur structure (le *sch√©ma*) change d'une ann√©e √† l'autre.

    ##### Principales Diff√©rences Constat√©es

    ###### 1. Incoh√©rence des Noms de Colonnes
    Les noms des colonnes pour une m√™me m√©trique ne sont pas standardis√©s.

    | Indicateur | 2015 | 2017 | 2019 |
    |-------------|------|------|------|
    | Score | Happiness Score | Happiness.Score | Score |
    | PIB | Economy (GDP per Capita) | Economy..GDP.per.Capita. | GDP per capita |
    | Soutien Social | Family | Family | Social support |
    | Confiance | Trust (Government Corruption) | Trust..Government.Corruption. | Perceptions of corruption |

    ###### 2. Incoh√©rence des Sch√©mas (Colonnes Manquantes ou Suppl√©mentaires)
    - **Region** : pr√©sente en 2015 et 2016, absente √† partir de 2017.  
    - **Colonnes statistiques** comme *Standard Error*, *Dystopia Residual* (2015-2017), *Lower/Upper Confidence Interval* (2016), ou *Whisker.high/low* (2017) apparaissent de mani√®re non uniforme.

    Ces irr√©gularit√©s compliquent toute tentative d'analyse comparative.
            
    ---

    #### La N√©cessit√© de l'Harmonisation

    Tenter de combiner ces fichiers *en l'√©tat* r√©sulterait en un **DataFrame inutilisable**, rempli de colonnes dupliqu√©es et de valeurs manquantes (*NaN*).  

    Pour mener √† bien notre analyse temporelle, un **processus d'harmonisation rigoureux** est donc un pr√©requis indispensable.

    ##### √âtapes du Processus d'Harmonisation

    1. **D√©finir un Sch√©ma Unifi√©** :  
    S√©lection d'un *noyau commun* de colonnes pertinentes (Score, PIB, Soutien Social, etc.) et suppression des colonnes statistiques non pertinentes.

    2. **Renommer et Nettoyer** :  
    Chargement de chaque fichier individuellement, puis renommage des colonnes pour qu'elles correspondent parfaitement √† notre sch√©ma unifi√©.

    3. **Enrichir les Donn√©es** :  
    - Ajout manuel d'une colonne *Year* √† chaque fichier (`df_2015['Year'] = 2015`).  
    - ‚ÄúR√©tro-ing√©nierie‚Äù de la colonne *Region* manquante pour 2017-2019 en utilisant les donn√©es de 2016 comme table de correspondance.

    4. **Concat√©ner** :  
    Empilement des 5 DataFrames harmonis√©s en un seul fichier final :  
    **`world_happiness_2015-2019_combined.csv`**.

    C'est ce jeu de donn√©es final et propre qui est utilis√© pour toutes les **visualisations interactives** du projet.

""")


# ==================================================================================================================
st.divider()
st.write("")
st.write("")
st.subheader("Harmonisation des dataframes")

with st.expander("D√©couvrir le code"):
    
    with st.echo():
        # R√©gularisation des dataframes
        # 1. D√©finition des dictionnaires de renommage pour chaque ann√©e
        COLS_2015 = {
            'Country': 'Country', 'Region': 'Region', 'Happiness Rank': 'Rank', 'Happiness Score': 'Score',
            'Economy (GDP per Capita)': 'GDP_per_Capita', 'Family': 'Social_Support',
            'Health (Life Expectancy)': 'Health_Life_Expectancy', 'Freedom': 'Freedom',
            'Trust (Government Corruption)': 'Trust_Government_Corruption', 'Generosity': 'Generosity'
        }
        COLS_2016 = {
            'Country': 'Country', 'Region': 'Region', 'Happiness Rank': 'Rank', 'Happiness Score': 'Score',
            'Economy (GDP per Capita)': 'GDP_per_Capita', 'Family': 'Social_Support',
            'Health (Life Expectancy)': 'Health_Life_Expectancy', 'Freedom': 'Freedom',
            'Trust (Government Corruption)': 'Trust_Government_Corruption', 'Generosity': 'Generosity'
        }
        COLS_2017 = {
            'Country': 'Country', 'Happiness.Rank': 'Rank', 'Happiness.Score': 'Score',
            'Economy..GDP.per.Capita.': 'GDP_per_Capita', 'Family': 'Social_Support',
            'Health..Life.Expectancy.': 'Health_Life_Expectancy', 'Freedom': 'Freedom',
            'Trust..Government.Corruption.': 'Trust_Government_Corruption', 'Generosity': 'Generosity'
        }
        COLS_2018 = {
            'Country or region': 'Country', 'Overall rank': 'Rank', 'Score': 'Score',
            'GDP per capita': 'GDP_per_Capita', 'Social support': 'Social_Support',
            'Healthy life expectancy': 'Health_Life_Expectancy', 'Freedom to make life choices': 'Freedom',
            'Perceptions of corruption': 'Trust_Government_Corruption', 'Generosity': 'Generosity'
        }
        COLS_2019 = COLS_2018 # 2019 est identique √† 2018

        # 2. Cr√©ation d'une liste vide pour stocker nos DataFrames nettoy√©s
        dfs_to_concat = []

        try:
            # --- 2015 ---
            df_2015 = df_2015[list(COLS_2015.keys())].rename(columns=COLS_2015)
            df_2015['Year'] = 2015
            dfs_to_concat.append(df_2015)
            st.write("Fichier 2015 trait√©.")
            
            # --- 2016 ---
            df_2016 = df_2016[list(COLS_2016.keys())].rename(columns=COLS_2016)
            df_2016['Year'] = 2016
            dfs_to_concat.append(df_2016)
            st.write("Fichier 2016 trait√©.")
            
            # Cr√©ation de la table de correspondance pour les R√©gions
            region_map = df_2016[['Country', 'Region']].drop_duplicates().set_index('Country')['Region']
            
            # --- 2017 ---
            df_2017 = df_2017[list(COLS_2017.keys())].rename(columns=COLS_2017)
            df_2017['Year'] = 2017
            df_2017['Region'] = df_2017['Country'].map(region_map)
            dfs_to_concat.append(df_2017)
            st.write("Fichier 2017 trait√© (r√©gions ajout√©es).")
            
            # --- 2018 ---
            df_2018 = df_2018[list(COLS_2018.keys())].rename(columns=COLS_2018)
            df_2018['Year'] = 2018
            df_2018['Region'] = df_2018['Country'].map(region_map)
            dfs_to_concat.append(df_2018)
            st.write("Fichier 2018 trait√© (r√©gions ajout√©es).")

            # --- 2019 ---
            df_2019 = df_2019[list(COLS_2019.keys())].rename(columns=COLS_2019)
            df_2019['Year'] = 2019
            df_2019['Region'] = df_2019['Country'].map(region_map)
            dfs_to_concat.append(df_2019)
            st.write("Fichier 2019 trait√© (r√©gions ajout√©es).")
            
            # 3. Concat√©nation
            df_final = pd.concat(dfs_to_concat, ignore_index=True)
            st.success("--- Concat√©nation termin√©e ! ---")
            
            # 4. V√©rification et Sauvegarde
            st.write(f"Dimensions du DataFrame final : {df_final.shape}")
            
            output_filename = "world_happiness_2015-2019_combined.csv"
            st.write(f"DataFrame final pr√™t (non sauvegard√© ici, mais disponible en t√©l√©chargement).")
            
            # Affichage du r√©sultat (df_final) √† l'int√©rieur de l'expander
            st.subheader("Aper√ßu du DataFrame Final Harmonis√©")
            st.dataframe(df_final.head())

        except KeyError as e:
            st.error(f"ERREUR : Une colonne attendue n'a pas √©t√© trouv√©e. V√©rifiez les dictionnaires de renommage.")
            st.error(e)
        except Exception as e:
            st.error(f"Une erreur inattendue est survenue : {e}")


st.markdown("""
    #### R√©capitulatif de l'Harmonisation des Donn√©es (2015-2019)
    L'objectif √©tait de combiner 5 fichiers CSV distincts (un pour chaque ann√©e de 2015 √† 2019) en un seul jeu de donn√©es coh√©sif. Une simple concat√©nation √©tait impossible car les noms de colonnes (le "sch√©ma") diff√©raient d'une ann√©e √† l'autre. Le processus suivant a √©t√© appliqu√© pour harmoniser et empiler les donn√©es sans perte de lignes.

    ##### Op√©ration 1 : D√©finition d'un Sch√©ma Unifi√© ("Colonnes Cl√©s")
    Justification : Pour analyser l'√©volution d'une m√©trique (comme le PIB) dans le temps, elle doit exister dans une seule et m√™me colonne. Nous avons donc d√©fini un "noyau commun" de colonnes pertinentes pr√©sentes, sous une forme ou une autre, dans tous les fichiers.

    Colonnes Conserv√©es (Sch√©ma Final) :
    Country (Pays)  
    * Region (R√©gion g√©ographique)  
    * Rank (Le classement)  
    * Score (Le score de bonheur)  
    * GDP_per_Capita (PIB par habitant)  
    * Social_Support (Soutien social/familial)  
    * Health_Life_Expectancy (Esp√©rance de vie en bonne sant√©)  
    * Freedom (Libert√© de faire des choix)  
    * Trust_Government_Corruption (Confiance envers le gouvernement / perception de la corruption)  
    * Generosity (G√©n√©rosit√©)  

    ---        

    ##### Op√©ration 2 : S√©lection et Renommage (Harmonisation)
    Justification : Chaque fichier a √©t√© charg√© individuellement, et ses colonnes ont √©t√© renomm√©es pour correspondre √† notre sch√©ma unifi√©. Les colonnes non pertinentes ont √©t√© intentionnellement supprim√©es.

    Exemples de Renommage :

    GDP_per_Capita (nouveau nom) provenait de :  
    * Economy (GDP per Capita) (en 2015, 2016)  
    * Economy..GDP.per.Capita. (en 2017)  
    * GDP per capita (en 2018, 2019)  

    Social_Support (nouveau nom) provenait de :  
    * Family (en 2015, 2016, 2017)  
    * Social support (en 2018, 2019)  

    Colonnes Principales Supprim√©es (et Ann√©es) :  
    * Standard Error (2015)  
    * Dystopia Residual (2015, 2016, 2017)  
    * Lower Confidence Interval, Upper Confidence Interval (2016)  
    * Whisker.high, Whisker.low (2017)  

    Justification de la Suppression : Ces colonnes √©taient des m√©tadonn√©es statistiques (comme les marges d'erreur) qui n'√©taient pas pr√©sentes de mani√®re coh√©rente dans tous les fichiers. Les conserver aurait cr√©√© un DataFrame final avec de nombreuses colonnes vides (NaN), polluant l'analyse temporelle. Nous avons privil√©gi√© le "noyau commun" de m√©triques.

    ---        

    ##### Op√©ration 3 : Cr√©ation de la Colonne Year
    Justification : Pour effectuer une analyse temporelle (comme px.line()), nous avions besoin d'une colonne indiquant l'ann√©e de chaque observation.

    Action : Une colonne Year a √©t√© ajout√©e √† chaque DataFrame avant la fusion (ex: df_2015['Year'] = 2015, df_2016['Year'] = 2016, etc.).

    ---        

    ##### Op√©ration 4 : R√©tro-ing√©nierie de la Colonne Region
    Justification : La colonne Region est cruciale pour le regroupement et la coloration des graphiques (ex: color='Region'). Cependant, elle n'√©tait explicitement pr√©sente que dans les fichiers de 2015 et 2016.

    Action :

    Une table de correspondance ("mapping") Pays -> R√©gion a √©t√© extraite du fichier de 2016 (qui √©tait complet).  
    Cette table a √©t√© utilis√©e pour "remplir" la colonne Region manquante dans les fichiers de 2017, 2018 et 2019, en se basant sur la colonne Country.  

    Note : Ce processus a r√©ussi √† r√©cup√©rer la majorit√© des r√©gions (764 sur 782), les 18 NaN restants correspondant √† des pays qui n'avaient pas de correspondance dans les donn√©es de 2016.

    ---        

    ##### Op√©ration 5 : Concat√©nation Verticale
    Justification : Assembler les 5 DataFrames (maintenant propres et harmonis√©s) en un seul grand DataFrame.  
    Action : La fonction pd.concat() a √©t√© utilis√©e pour "empiler" verticalement les DataFrames.  
    R√©sultat : Un DataFrame unique de 782 lignes (158 + 157 + 155 + 156 + 156) et 11 colonnes (les 10 du sch√©ma + Year), ne conservant que les NaN qui existaient dans les donn√©es sources ou qui n'ont pas pu √™tre mapp√©s (pour Region). 
    
    **Aucune ligne n'a √©t√© perdue.**
            
    ---
            
    ##### Conclusion
    On obtient un dataframe avec toutes les colonnes importantes et exploitables.
""")


# Cr√©ation de colonnes
st.write("")
st.markdown("""T√©l√©chargez le nouveau dataframe et passez √† la visualisation avec Plotly""")
col_next1, col_next2 = st.columns(2)

# Telechargement du fichier harmonis√©
@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

csv_data = convert_df_to_csv(df_final) 


with col_next1 :
    st.download_button(
        label="T√©l√©chargez le nouveau DataFrame en CSV",
        data=csv_data, 
        file_name="world_happiness_2015-2019_combined.csv",
        mime="text/csv",
        icon="üóíÔ∏è",
        use_container_width=True
    )

with col_next2 :
    st.link_button(
        "Les graphiques interactifs avec Plotly", 
        url="/Partie_2_-_Visualisation_avec_Plotly", 
        icon="‚û°Ô∏è",
        use_container_width=True
    )